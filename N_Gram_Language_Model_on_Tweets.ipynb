{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHNYJPXL2BoA"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO-HvY4uu66u",
        "outputId": "ef366417-c915-421c-90f1-7dbce3b40387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in c:\\users\\8psco\\anaconda3\\lib\\site-packages (4.5.0)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.0.0 in c:\\users\\8psco\\anaconda3\\lib\\site-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\8psco\\anaconda3\\lib\\site-packages (from tweepy) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\8psco\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\8psco\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\8psco\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\8psco\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\8psco\\anaconda3\\lib\\site-packages (from requests-oauthlib<2,>=1.0.0->tweepy) (3.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tweepy --upgrade\n",
        "\n",
        "import tweepy\n",
        "import random\n",
        "import configparser\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import html\n",
        "from termcolor import colored\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuNWPe8iXlKb"
      },
      "source": [
        "# Download and Clean Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load tweepy client and read api keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eSw0aNcH-IiV"
      },
      "outputs": [],
      "source": [
        "config = configparser.ConfigParser()\n",
        "config.read('config.ini')\n",
        "tokens = config['Tokens']\n",
        "client = tweepy.Client(\n",
        "  bearer_token=tokens['BearerToken'],\n",
        "  consumer_key=tokens['ConsumerKey'],\n",
        "  consumer_secret=tokens['ConsumerSecret'],\n",
        "  access_token=tokens['AccessToken'],\n",
        "  access_token_secret=tokens['AccessTokenSecret'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download tweets of followed users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwelqwIAD38x",
        "outputId": "ffa8191d-60eb-4d9d-8282-aac7beab0abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving @redlettermedia's tweets (615/615).............\n",
            "Total tweets retrieved: 299759\n"
          ]
        }
      ],
      "source": [
        "tweets = []\n",
        "\n",
        "# get user ids of a specified user's followed accounts\n",
        "root_user = client.get_users(usernames='redlettermedia').data[0] # twitter account of one of my favorite YouTube channels, Red Letter Media\n",
        "following = client.get_users_following(root_user['id'], max_results=1000).data\n",
        "users = [(user['username'], user['id']) for user in following]\n",
        "users.append((root_user['username'], root_user['id']))\n",
        "\n",
        "# get tweets for each user id\n",
        "for i, (username, user_id) in enumerate(users):\n",
        "  print(f'Retrieving @{username}\\'s tweets ({i+1}/{len(users)})............', end='\\r')\n",
        "  users_tweets = []\n",
        "  until_id = None\n",
        "  repeat_count = 0\n",
        "  while repeat_count < 50:\n",
        "    try:\n",
        "      users_tweets = client.get_users_tweets(\n",
        "        user_id,\n",
        "        exclude=['retweets', 'replies'], \n",
        "        max_results=100,\n",
        "        until_id=until_id,\n",
        "      )\n",
        "      if users_tweets[0]:\n",
        "        until_id = users_tweets[0][-1]['id']\n",
        "        tweets += list(map(lambda x: x['text'], users_tweets[0]))\n",
        "        repeat_count += 1\n",
        "      else:\n",
        "        break\n",
        "    except:\n",
        "      print(f'Waiting for cooldown to end ({i+1}/{len(users)})............', end='\\r')\n",
        "      time.sleep(30)\n",
        "\n",
        "np.save('tweets.npy', tweets)\n",
        "print(f'\\nTotal tweets retrieved: {len(tweets)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print subset of tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many do you remember?https://t.co/mp8Cvwgh94\n",
            "\n",
            "Alright which one of you degenerates is trying to log into my Fortnite account?\n",
            "\n",
            "It's #MogwaiMonday! RT this if you wish you got a Gizmo for Xmas!!\n",
            "\n",
            "#GREMLINS #Forever #gizmowish #gremlins3 ? https://t.co/qFQrCuz6sq\n",
            "\n",
            "https://t.co/phfWHXxDze\n",
            "\n",
            "My mom's face when I introduced her to #TheBoysTV https://t.co/6YOjJ1NgUS\n",
            "\n",
            "Grindcore: Mad at Zimmer\n",
            "Galaxy Gate: Mad at Rick\n",
            "Castles in the Sky: Mad at Kirk\n",
            "Furious: Mad at Everybody\n",
            "\n",
            "Mixed Messages is now available to all Surly markets. https://t.co/RsE0hvoLRB\n",
            "\n",
            "I notice they didnâ€™t put ass on the listâ€¦ðŸ˜‰ https://t.co/7iXFyJDSLW\n",
            "\n",
            "Alright it's time, I'm finally going to learn clip studio paint.  Anyone recommend any tutorials they've used?\n",
            "\n",
            "https://t.co/Ts2S6UvQlq https://t.co/E7cjLI9mWi\n",
            "\n",
            "Boom goes the dynamite. Big reveal, @RickandMorty fans. Iâ€™ll be appearing at @IndyPopCon on Saturday, June 8th in Indianapolis.  Letâ€™s hang out!\n",
            "#popcon #popconindy #me #rickandmorty #indysquanchcon #picklerick #lemongrab #troversavestheuniverse\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_tweets(tweets, indices):\n",
        "    for tweet in np.array(tweets)[indices]:\n",
        "        if len(tweet) > 0:\n",
        "            print(tweet)\n",
        "            print()\n",
        "\n",
        "random_indices = list(np.random.choice(len(tweets), size=10, replace=False))\n",
        "\n",
        "print_tweets(tweets, random_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clean up tweets for n-gram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3cOCbicT8HM",
        "outputId": "be29b653-2fa5-40cf-ebcf-5f16084e6d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "how many do you\n",
            "\n",
            "alright which one of you degenerates is trying to log into my fortnite account ? \n",
            "\n",
            "it's #mogwaimonday ! rt this if you wish you got a gizmo for xmas ! ! #gremlins #forever #gizmowish #gremlins3 ? \n",
            "\n",
            "my mom's face when i introduced her to #theboystv\n",
            "\n",
            "grindcore : mad at zimmer galaxy gate : mad at rick castles in the sky : mad at kirk furious : mad at everybody mixed messages is now available to all surly markets . \n",
            "\n",
            "i notice they didn't put ass on the list . . . ðŸ˜‰ \n",
            "\n",
            "alright it's time , i'm finally going to learn clip studio paint . anyone recommend any tutorials they've used ? \n",
            "\n",
            "boom goes the dynamite . big reveal , @rickandmorty fans . i'll be appearing at @indypopcon on saturday , june 8th in indianapolis . let's hang out ! #popcon #popconindy #me #rickandmorty #indysquanchcon #picklerick #lemongrab #troversavestheuniverse\n",
            "\n",
            "----\n",
            "\n",
            "Total tweets after cleaning: 280388\n"
          ]
        }
      ],
      "source": [
        "def clean_tweet(tweet):\n",
        "  tweet = remove_links(tweet)\n",
        "  tweet = html.unescape(tweet)\n",
        "  tweet = tweet.replace('â€¦', '...') # replace ellipsis symbol\n",
        "  tweet = re.sub(r'[â€™â€˜]', '\\'', tweet) # replace nonstandard single quotes\n",
        "  tweet = re.sub(r'[\\{\\}\\[\\]\\(\\)\"â€œâ€]', '', tweet) # remove brackets, parenthesis, and quotes\n",
        "  tweet = re.sub(r'([^\\w\\s@#_/\\'-])', r' \\1 ', tweet) # separate punctuation\n",
        "  tweet = re.sub(r'\\s+', ' ', tweet) # replace excessive whitespace\n",
        "  tweet = tweet.lower()\n",
        "  return tweet\n",
        "\n",
        "def remove_links(tweet):\n",
        "  split_tweet = tweet.split()\n",
        "  split_tweet = [split_str for split_str in split_tweet if not is_link(split_str)]\n",
        "  tweet = ' '.join(split_tweet)\n",
        "  return tweet\n",
        "\n",
        "def is_link(string):\n",
        "  return 'https://' in string or 'http://' in string\n",
        "\n",
        "cleaned_tweets = [clean_tweet(tweet) for tweet in tweets]\n",
        "print_tweets(cleaned_tweets, random_indices)\n",
        "\n",
        "cleaned_tweets = list(set([tweet for tweet in cleaned_tweets if len(tweet) > 0]))\n",
        "np.save('cleaned_tweets.npy', cleaned_tweets)\n",
        "print(f'----\\n\\nTotal tweets after cleaning: {len(cleaned_tweets)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI02-U5C_Nvr"
      },
      "source": [
        "# Create N-gram Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$P(token_i \\mid token_{i-n+1:i-1})=\\dfrac{Count(token_{i-n+1:i})}{Count(token_{i-n+1:i-1})}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VfKp6MoCbyeS"
      },
      "outputs": [],
      "source": [
        "START = '<SOT>'\n",
        "STOP = '<EOT>'\n",
        "\n",
        "class TweetModel:\n",
        "  def __init__(self, tweets, n):\n",
        "    self.n = n\n",
        "    self.counts = Counter()\n",
        "    self.context_counts = Counter()\n",
        "    self.process_tweets(tweets)\n",
        "\n",
        "  def process_tweets(self, tweets):\n",
        "    tokenized_tweets = [tweet.split() for tweet in tweets]\n",
        "    for tweet in tokenized_tweets:\n",
        "      if len(tweet) > 0:\n",
        "        tweet_ngrams = self.create_ngrams(tweet)\n",
        "        for ngram in tweet_ngrams:\n",
        "          self.counts[ngram] += 1\n",
        "    for (context, _), count in self.counts.items():\n",
        "      self.context_counts[context] += count\n",
        "\n",
        "  def random_tweet(self, format=True):\n",
        "    start_context = [START] * (self.n - 1)\n",
        "    curr_context = start_context\n",
        "    tweet, probs = [], []\n",
        "    probs = []\n",
        "    while True:\n",
        "      token, prob = self.random_token(tuple(curr_context))\n",
        "      if token == STOP:\n",
        "        break\n",
        "      tweet.append(token)\n",
        "      probs.append(prob)\n",
        "      curr_context.pop(0)\n",
        "      curr_context.append(token)\n",
        "      if len(' '.join(tweet)) > 280:\n",
        "        curr_context = start_context\n",
        "        tweet, probs = [], []\n",
        "    if format:\n",
        "      tweet = ' '.join(tweet) + ' '\n",
        "      tweet = re.sub(r'(\\S) ([\\?!:;,\\.])', r'\\1\\2', tweet) # line needs to be repeated twice to work properly\n",
        "      tweet = re.sub(r'(\\S) ([\\?!:;,\\.])', r'\\1\\2', tweet)\n",
        "      tweet.strip()\n",
        "    return tweet, probs\n",
        "\n",
        "  def random_token(self, context):\n",
        "    tokens = [token for (context1, token), _ in self.counts.items() if context == context1]\n",
        "    rand = random.random()\n",
        "    random_token = None\n",
        "    total = 0\n",
        "    for token in tokens:\n",
        "      random_token = token\n",
        "      total += self.counts[(context, token)] / self.context_counts[context]\n",
        "      if total > rand:\n",
        "        break\n",
        "    return random_token, self.counts[(context, random_token)] / self.context_counts[context]\n",
        "\n",
        "  def create_ngrams(self, tokens):\n",
        "    ngrams = []\n",
        "    for i in range(len(tokens) + 1):\n",
        "        context = []\n",
        "        for j in range(self.n - 1, 0, -1):\n",
        "            if i - j < 0:\n",
        "                context.append(START)\n",
        "            else:\n",
        "                context.append(tokens[i - j])\n",
        "        if i == len(tokens):\n",
        "            ngrams.append((tuple(context), STOP))\n",
        "        else:\n",
        "            ngrams.append((tuple(context), tokens[i]))\n",
        "    return tuple(ngrams)\n",
        "\n",
        "  def print_counts(self, n):\n",
        "    print(f'TOTAL UNIQUE NGRAMS: {len(self.counts)}')\n",
        "    print(f'TOP {n} NGRAMS:')\n",
        "    counts = self.counts.items()\n",
        "    counts = sorted(counts, key=lambda x: x[1], reverse=True)\n",
        "    for count in counts[:n]:\n",
        "      print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trigram model:\n",
        "\n",
        "$P(token_i \\mid token_{i-2:i-1})=\\dfrac{Count(token_{i-2:i})}{Count(token_{i-2:i-1})}$\n",
        "\n",
        "e.g. $P(\\text{is}\\mid\\text{my name})=\\dfrac{Count(\\text{my name is})}{Count(\\text{my name})}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WVU1yBo1mK-a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOTAL UNIQUE NGRAMS: 3610235\n",
            "TOP 20 NGRAMS:\n",
            "((('.', '.'), '.'), 32131)\n",
            "((('<SOT>', '<SOT>'), 'the'), 13361)\n",
            "((('<SOT>', '<SOT>'), 'i'), 12705)\n",
            "((('.', '.'), '<EOT>'), 10179)\n",
            "((('!', '!'), '!'), 9405)\n",
            "((('<SOT>', '<SOT>'), 'this'), 6856)\n",
            "((('!', '!'), '<EOT>'), 4602)\n",
            "((('<SOT>', '<SOT>'), \"it's\"), 4404)\n",
            "((('<SOT>', '<SOT>'), 'we'), 4089)\n",
            "((('<SOT>', '<SOT>'), 'a'), 3938)\n",
            "((('<SOT>', '<SOT>'), '.'), 3608)\n",
            "((('<SOT>', '<SOT>'), 'happy'), 3548)\n",
            "((('<SOT>', '<SOT>'), 'if'), 3261)\n",
            "((('<SOT>', '<SOT>'), 'my'), 3054)\n",
            "((('<SOT>', '<SOT>'), \"i'm\"), 2788)\n",
            "((('<SOT>', 'this'), 'is'), 2578)\n",
            "((('<SOT>', '<SOT>'), 'just'), 2455)\n",
            "((('<SOT>', '<SOT>'), 'you'), 2387)\n",
            "((('<SOT>', '<SOT>'), 'what'), 2350)\n",
            "((('<SOT>', '<SOT>'), 'new'), 2312)\n"
          ]
        }
      ],
      "source": [
        "tweets = np.load('cleaned_tweets.npy')\n",
        "\n",
        "model = TweetModel(tweets=tweets, n=3)\n",
        "model.print_counts(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Q7Ipoz9ZnO"
      },
      "source": [
        "# Generate tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "m7S_4EiWfdzU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| the academy awards.....                                    |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| that's a wrap on day 11 of 11 emmy awards will b honored   |\n",
            "| with 7 you'll be watching! i hope now that i don't pay     |\n",
            "| full price again he will spend millions of dollars. health |\n",
            "| care charities. order yours right away. we were drunk      |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| this is pizza                                              |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| can't wait to get a question for mark who is a villain     |\n",
            "| without an umbrella.                                       |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| thanks for having me on raya. order & enter promocode      |\n",
            "| mkebrewfest for a @googleplay users choice award,          |\n",
            "| earthers: #scififantasyshowof2018                          |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| , @camkendell. if ur around, and enjoy a yogurt.           |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| yes! i know it. ðŸ™ƒ                                          |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| because toronto would line up for having me @kermodemovie  |\n",
            "| & team -electronic soundtrack -jeff goldbloom nails it.    |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| the performances are mark standing on a first responder    |\n",
            "| has its world premiere on desus & mero | showtime via      |\n",
            "| @youtube happy fourth! a bumbag. lolll                     |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n",
            "+------------------------------------------------------------+\n",
            "| +-------+                                                  |\n",
            "| |  ! !  | N-Gram Bot @ngrambot - 12h                       |\n",
            "| | [O_O] |                                                  |\n",
            "| |  | |  |                                                  |\n",
            "| +-------+                                                  |\n",
            "|                                                            |\n",
            "| it's so star wars youtube for good! i learned that         |\n",
            "| congresswoman victoria neuman announces fbsa hire -where   |\n",
            "| is alastair?:                                              |\n",
            "|                                                            |\n",
            "| <3 31.4k                                                   |\n",
            "+------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "def print_tweet(tweet):\n",
        "  print('+------------------------------------------------------------+')\n",
        "  print('| +-------+                                                  |')\n",
        "  print('| |  ! !  | N-Gram Bot @ngrambot - 12h                       |')\n",
        "  print('| | [O_O] |                                                  |')\n",
        "  print('| |  | |  |                                                  |')\n",
        "  print('| +-------+                                                  |')\n",
        "  print('|                                                            |')\n",
        "\n",
        "  for line in tweet_to_lines(tweet):\n",
        "    padding = ' ' * (59 - len(line))\n",
        "    print('| ' + line + padding + '|')\n",
        "\n",
        "  print('|                                                            |')\n",
        "  print('| <3 31.4k                                                   |')\n",
        "  print('+------------------------------------------------------------+')\n",
        "\n",
        "def tweet_to_lines(tweet):\n",
        "  lines = []\n",
        "  curr_line = ''\n",
        "  for token in tweet.split():\n",
        "    if len(curr_line) + len(token) + 1 <= 59:\n",
        "      curr_line += token + ' '\n",
        "    else:\n",
        "      lines.append(curr_line)\n",
        "      curr_line = token + ' '\n",
        "  lines.append(curr_line)\n",
        "  return lines\n",
        "\n",
        "for i in range(10):\n",
        "  random_tweet, _ = model.random_tweet()\n",
        "  print_tweet(random_tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display token probabilities for randomly generated tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Legend\n",
            "\u001b[32mHigh Likelihood [75%, 100%]\u001b[0m\n",
            "\u001b[36mMedium-High Likelihood [50%, 75%)\u001b[0m\n",
            "\u001b[33mLow-Medium Likelihood [25%, 50%)\u001b[0m\n",
            "\u001b[31mLow Likelihood [0%, 25%)\u001b[0m\n",
            "\n",
            "\u001b[31mwilly\u001b[0m \u001b[36mwonka\u001b[0m \u001b[33mand\u001b[0m \u001b[32mthe\u001b[0m \u001b[31mcontext\u001b[0m \u001b[31m;\u001b[0m \u001b[32mthe\u001b[0m \u001b[31mbeatles\u001b[0m \u001b[31m.\u001b[0m \u001b[31mbut\u001b[0m \u001b[31mthis\u001b[0m \u001b[31mwas\u001b[0m \u001b[31mone\u001b[0m \u001b[32mof\u001b[0m \u001b[33mthe\u001b[0m \u001b[31mdiary\u001b[0m \u001b[36mof\u001b[0m \u001b[32ma\u001b[0m \u001b[31msignificant\u001b[0m \u001b[31mrole\u001b[0m \u001b[32min\u001b[0m \u001b[31msteven\u001b[0m \u001b[32mspielberg's\u001b[0m \u001b[32m#westsidestory\u001b[0m \u001b[31mtimeless\u001b[0m \u001b[32m.\u001b[0m "
          ]
        }
      ],
      "source": [
        "def token_color(token_prob):\n",
        "  if token_prob >= 0.75:\n",
        "    return 'green'\n",
        "  elif token_prob >= 0.5:\n",
        "    return 'cyan'\n",
        "  elif token_prob >= 0.25:\n",
        "    return 'yellow'\n",
        "  else:\n",
        "    return 'red'\n",
        "\n",
        "random_tweet, probs = model.random_tweet(format=False)\n",
        "\n",
        "print('Legend')\n",
        "print(colored('High Likelihood [75%, 100%]', token_color(0.75)))\n",
        "print(colored('Medium-High Likelihood [50%, 75%)', token_color(0.5)))\n",
        "print(colored('Low-Medium Likelihood [25%, 50%)', token_color(0.25)))\n",
        "print(colored('Low Likelihood [0%, 25%)', token_color(0.0)))\n",
        "print()\n",
        "\n",
        "for token, prob in zip(random_tweet, probs):\n",
        "  print(colored(token, token_color(prob)), end=' ')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "N-Gram Language Model on Tweets",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
